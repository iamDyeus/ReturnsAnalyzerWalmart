{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Import Necessary Libraries"
      ],
      "metadata": {
        "id": "YJYOoP6K2e8r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCOcoKVT1gry"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sqlalchemy import create_engine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import xgboost as xgb\n",
        "import joblib\n",
        "import shap"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load Data from Database"
      ],
      "metadata": {
        "id": "VHNGh9Na2eHY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Database connection setup\n",
        "engine = create_engine('mysql+pymysql://username:password@host/dbname')\n",
        "\n",
        "# Query to fetch data from the primary table\n",
        "query = \"\"\"\n",
        "SELECT\n",
        "    p.Depot_ID, v.Vehicle_ID, d.Driver_ID, pr.Product_ID,\n",
        "    p.Weather_Score, p.Delivery_Status,\n",
        "    dt.Depot_Integrity_Score, dt.Success_to_Delivery_Ratio AS Depot_Success_Ratio,\n",
        "    vt.Vehicle_Integrity_Score, vt.Success_to_Delivery_Ratio AS Vehicle_Success_Ratio,\n",
        "    dr.Driver_Performance_Score, dr.Success_to_Delivery_Ratio AS Driver_Success_Ratio,\n",
        "    pt.Product_Type, pt.Type_Liability, pt.Product_Score, pt.Success_to_Delivery_Ratio AS Product_Success_Ratio\n",
        "FROM PrimaryTable p\n",
        "JOIN DepotTable dt ON p.Depot_ID = dt.Depot_ID\n",
        "JOIN VehicleTable vt ON p.Vehicle_ID = vt.Vehicle_ID\n",
        "JOIN DriverTable dr ON p.Driver_ID = dr.Driver_ID\n",
        "JOIN ProductTable pt ON p.Product_ID = pt.Product_ID\n",
        "\"\"\"\n",
        "data = pd.read_sql(query, engine)"
      ],
      "metadata": {
        "id": "u9OLjNyB2oZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preprocessing"
      ],
      "metadata": {
        "id": "J8ewtxug2opr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle missing values (if any)\n",
        "data = data.dropna()  # Alternatively, use data.fillna() for imputation\n",
        "\n",
        "# One-hot encode categorical features\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "encoded_product_type = encoder.fit_transform(data[['Product_Type']])\n",
        "encoded_columns = encoder.get_feature_names_out(['Product_Type'])\n",
        "\n",
        "# Add encoded features to the data\n",
        "encoded_df = pd.DataFrame(encoded_product_type, columns=encoded_columns)\n",
        "data = pd.concat([data, encoded_df], axis=1).drop('Product_Type', axis=1)\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop('Delivery_Status', axis=1)\n",
        "y = data['Delivery_Status']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "9skeUUii2rq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Training"
      ],
      "metadata": {
        "id": "gr10srUg2sId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "accuracy = model.score(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "4Mo_otqk2yFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Save the Trained Model"
      ],
      "metadata": {
        "id": "eoKNwG9v2yVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model_filename = 'xgboost_delivery_model.pkl'\n",
        "joblib.dump(model, model_filename)"
      ],
      "metadata": {
        "id": "2tHSi-vL23c9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SHAP Analysis"
      ],
      "metadata": {
        "id": "6Af7JeE-24EG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a SHAP explainer\n",
        "explainer = shap.Explainer(model, X_train)\n",
        "\n",
        "# Calculate SHAP values for the test set\n",
        "shap_values = explainer(X_test)"
      ],
      "metadata": {
        "id": "OkIZpb3829Ek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Identify the Most Impactful Feature for Failures"
      ],
      "metadata": {
        "id": "d_MRwu3n29cU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the indices of failed predictions\n",
        "failed_indices = np.where(model.predict(X_test) == 0)[0]\n",
        "\n",
        "# Store the most impactful feature for each failed prediction\n",
        "impactful_features = []\n",
        "\n",
        "for idx in failed_indices:\n",
        "    # Get SHAP values for the failed prediction\n",
        "    shap_value = shap_values[idx].values\n",
        "    feature_impact = pd.Series(shap_value, index=X_test.columns)\n",
        "\n",
        "    # Find the feature with the maximum negative impact (leading to failure)\n",
        "    most_impactful_feature = feature_impact.idxmin()\n",
        "    impactful_features.append(most_impactful_feature)\n",
        "\n",
        "# Create a DataFrame to summarize results\n",
        "failure_analysis = pd.DataFrame({\n",
        "    'Index': failed_indices,\n",
        "    'Most Impactful Feature': impactful_features\n",
        "})\n",
        "\n",
        "# Display the results\n",
        "print(failure_analysis)"
      ],
      "metadata": {
        "id": "9Z4S1trq3BDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Summary of Most Common Failure Causes"
      ],
      "metadata": {
        "id": "gPZi-S5p3BSc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Aggregate the most impactful features\n",
        "feature_failure_counts = failure_analysis['Most Impactful Feature'].value_counts()\n",
        "\n",
        "# Display the features that most often lead to failure\n",
        "print(\"Most Common Features Leading to Failure:\")\n",
        "print(feature_failure_counts)\n"
      ],
      "metadata": {
        "id": "UGeC_hrf3G-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save Failure Analysis Results"
      ],
      "metadata": {
        "id": "m16H38uX3HP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the analysis results to a CSV file\n",
        "failure_analysis.to_csv('failure_analysis.csv', index=False)"
      ],
      "metadata": {
        "id": "pcO-IUau3Mbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "bihari DB banade uske bina mai bss yeh module de sakta hu"
      ],
      "metadata": {
        "id": "uQCbLgg64qoW"
      }
    }
  ]
}